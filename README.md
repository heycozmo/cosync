<div align="center">
  <h1>ðŸ§  cosync</h1>
  <p><strong>local ai assistant built to think, speak, and act â€” your personal jarvis, powered by ollama.</strong></p>
  <img src="https://img.shields.io/badge/version-v1.0--alpha-blue.svg" alt="version badge">
  <img src="https://img.shields.io/badge/python-3.10+-yellow.svg" alt="python version">
  <img src="https://img.shields.io/badge/status-active-success.svg" alt="status badge">
</div>

---

## ðŸš€ overview

**cosync** is a locally hosted ai assistant that runs directly on your pc â€” no external servers, no data sharing.  
it listens, speaks, and performs actions through modular tools like spotify control, logging, and local llm reasoning.

its goal: to feel *alive* on your system â€” capable of reacting, remembering, and assisting, just like a real digital companion.

---

## ðŸ§© current version â€” v1 (core loop)

### âœ… features
- ðŸ§  local llm integration â€” connects to [ollama](https://ollama.ai/) (llama3 by default)
- ðŸ”€ command routing â€” routes between user intent (commands vs. questions)
- ðŸŽµ spotify control â€” play, pause, skip, get track info
- ðŸ”Š text-to-speech â€” offline voice output via pyttsx3
- ðŸ§¾ logging system â€” structured jsonl event logs
- âš™ï¸ modular design â€” extendable for future systems (pulse, memory, dashboard, etc.)

### ðŸ—‚ folder structure
cosync/
â”‚
â”œâ”€â”€ main.py               # core loop (routing + input/output)
â”œâ”€â”€ llm.py                # handles local ollama prompts
â”œâ”€â”€ commands.py           # command detection + dispatch
â”œâ”€â”€ spotify_control.py    # spotify connect actions
â”œâ”€â”€ text_to_speech.py     # voice output (pyttsx3)
â”œâ”€â”€ speech_to_text.py     # placeholder for future mic input
â”œâ”€â”€ logger.py             # jsonl logging system
â””â”€â”€ README.md

---

## ðŸ§­ roadmap

### ðŸ©µ v1 â€” local assistant core
- [x] local llm (ollama llama3)
- [x] core routing
- [x] spotify control
- [x] tts voice output
- [ ] stt input
- [ ] memory system
- [ ] pulse diagnostic system
- [ ] localhost dashboard
- [ ] safety / confirmation layer

### ðŸ©¶ v2 â€” remote access & context
- ðŸŒ use anywhere via email or api calls  
- ðŸ” voice id + passcode for secure access  
- ðŸ•µï¸ proactive â€œpulseâ€ context awareness  
- ðŸ“± device sync + presence detection  

### ðŸ©µ v3 â€” autonomous companion
- ðŸ’¬ conversational awareness (follow-ups, context memory)
- âš™ï¸ proactive behavior (initiate convos, give updates)
- ðŸ–¥ï¸ full dashboard with activity timeline + insights
- ðŸ¤– task automation (order food, send messages, etc.)

---

## ðŸ›  setup

### prerequisites
- python 3.10+
- [ollama](https://ollama.ai/) installed and running locally  
- spotify developer app (client id + secret)
- required python libs:
  pip install requests spotipy pyttsx3 psutil

### running cosync
ollama serve
python main.py

---

## ðŸ’¬ example interaction
you: pause the music  
cosync: paused spotify.

you: what are you  
cosync: i am llama3, a local ai model trained to assist and converse naturally.

---

## ðŸ§  about
cosync is built by **cos** as a long-term personal ai project â€” designed for privacy, customization, and local control.  
itâ€™s an ongoing experiment to merge llms, automation, and real-world utility into a single, self-contained system.

> "cosync isn't just an assistant â€” it's a local ecosystem."

---

<div align="center">
  <sub>built with ðŸ§ , â˜•, and a bit of chaos â€¢ 2025</sub>
</div>